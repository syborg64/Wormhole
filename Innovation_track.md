<style>
  blockquote {
  border-left: .25em solid #888;
  border-left-color: lightblue;
}
</style>

# Wormhole

## Contexte

Le projet Wormhole est n√© de la n√©cessit√© de simplifier l'acc√®s et la gestion des donn√©es entre plusieurs serveurs. Actuellement, les entreprises sont confront√©es √† plusieurs d√©fis li√©s √† la centralisation ou √† la d√©centralisation des donn√©es. Les solutions centralis√©es pr√©sentent des risques de s√©curit√©, des limitations d'acc√®s et un poids accru sur l'infrastructure. En revanche, les infrastructures d√©centralis√©es sont difficiles √† mettre en place et manquent de solutions universelles.  

Wormhole se positionne comme une solution technique innovante visant √† offrir un moyen simple et universel de construire une infrastructure d√©centralis√©e adapt√©e, s√©curis√©e et souveraine pour ses donn√©es. Le projet vise √† r√©pondre aux besoins de s√©curit√©, de flexibilit√© et de simplicit√© de configuration pour les entreprises et les particuliers.  

## Sp√©cification Technique
Comme expliqu√© dans le contexte du projet, Wormhole est une solution de **stockage d√©centralis√© de donn√©es**, c'est √† dire un stockage sur plusieurs machines distinctes et non sur une seule machine centrale.   
Cette partie du document propose une rapide explication de ce qu'est la d√©centralisation, et de comment cette m√©thode se compare aux autres.   
Le d√©tail technique des fonctions propos√©es par le projet ainsi que sa stack technique sera ensuite abord√©.  

### La d√©centralisation (contexte - d√©finition - utilit√©)
Aujoud'hui, petites comme grandes entreprises ont de grands besoins en terme de stockage de donn√©es :
- **Donn√©es internes**
  - Documents de l'entreprise (cloud interne pour les employ√©s)
  - Donn√©es de travail   
    > Assets pour un studio de jeu vid√©o   
    > Datasets scientifiques pour un laboratoire   
    > Training sets pour studios d'intelligence artificielle   
    > Big Data   
    > ... toute donn√©e servant directement l'entreprise   
  - Donn√©es sensibles
    > Comptes, devis et factures de l'entreprise (donn√©es l√©gales)   
    > Donn√©es priv√©es en rapport avec un client   
- **Donn√©es utilis√©s par un service logiciel propos√© par l'entreprise**
  > Musiques pour une application comme Spotify/Deezer   
  > Vid√©os pour une application comme Youtube/TikTok   
  > Diverses donn√©es stock√©es pour un service comme OneDrive/Google Drive   

Tous ces usages ne sont que des exemples mais repr√©sentent bien les besoins qu'ont les entreprises correctement implant√©s dans l'√®re informatique.   
**Cependant, ce besoin est vite limit√© par une limite physique.**   
En effet, on ne peut pas concentrer une infinit√© de ressources dans un seul serveur.   
Centraliser la donn√©e sur une seule machine poserait aussi un probl√®me d'int√©grit√© des donn√©es en cas de panne.   

**Tr√®s vite arrive la n√©c√©ssit√© d'augmenter le nombre de machines pour r√©pondre au moins √† certaines des exigences suivantes :**
- Besoin de capacit√© massive de stockage (plus de place)
- Besoin de plus de puissance (servir les donn√©es plus vite)
- Fiabilit√© / Gestion de crise
  - R√©sister sans effort aux pannes mineures
  - Suivre sa politique de PCA/PCI ([Plan de Continuit√© d'activit√© Informatique](https://fr.wikipedia.org/wiki/Plan_de_continuit%C3%A9_d%27activit%C3%A9_(informatique))) en cas d'incidant majeur
- Faciliter l'acc√®s pour tous les sites g√©ographiques de l'entreprise

> [!TIP] Plan de Continuit√© d'Activit√© / Informatique
> La **PCA/PCI** est une pratique courante pour les entreprises d√©pendantes de services informatiques.   
> G√©n√©ralement mise en place par la direction informatique ainsi que les coeurs de m√©tiers concern√©s, elle prend la forme d'une proc√©dure claire de r√©action aux incidents graves les plus probables.   
> Wormhole n'√©crit pas ce plan pour l'entreprise, mais dispose des param√®tres n√©c√©ssaire pour respecter des proc√©dures d√©finies √† l'avance.   
> Plus d'informations : [Wikip√©dia - Plan de continuit√© d'activit√© (informatique)](https://fr.wikipedia.org/wiki/Plan_de_continuit%C3%A9_d%27activit%C3%A9_(informatique))

Multiplier le nombre de machines pour un m√™me service s'appelle de la d√©centralisation, par opposition √† la centralisation, restreinte √† une entit√©.   
Face √† ce besoin incontournable, les entreprises ont peu de solutions :
- **Utiliser un fournisseur cloud externe**   
  > C'est la solution la plus simple.   
  > Elle est cependant couteuse et l'entreprise n'est plus souveraine de ses donn√©es.   
  > Cela la rend impossible dans certains cas (donn√©es sensibles, donn√©es utilis√©es par un service logiciel ou besoin sp√©cifique)   
  > *A noter que les services cloud utilisent justement la d√©centralisation pour s√©curiser les donn√©es*
- **Semi-centralisation (manuelle)**   
  > Solution consistant √† garder le plus possible une entit√©e centralis√©e (serveur / salle serveur) principale, et d'en pr√©voir une seconde hors ligne sur laquelle on sauvegarde r√©guli√®rement.   
  > En cas de panne, on connecte la seconde entit√© en remplacement. On l'utilisera aussi pour remettre les donn√©es sur l'entit√© principale une fois celle ci en √©tat de marche.   
  > Cette strat√©gie est plus utilis√©e sur les infrastructures √† √©chelle datacenter. Peu accessible par les entreprises moyennes.   
  > Elle induit aussi une possible interruption de service.  
- **D√©centralisation (manuelle)**   
  > **La solution ultime**, r√©pondant √† tous les besoins dont nous avons parl√©.   
  > **Cependant il n'existe pas de moyen universel pour mettre en place cette solution. C'est √† cela que Wormhole r√©pond,** en proposant un outil simple, ouvert et universel.  

> [!TIP] Wormhole se veut √™tre le Kubernetes de l'espace disque.  

### Notre solution : Wormhole
**Wormhole offre une solution simple et d√©clarative pour la cr√©ation d'infrastructures d√©centralis√©es simples comme avanc√©es.**   
Wormhole cr√©√© un syst√®me de fichiers d√©centralis√© entre toutes les machines ajout√©s au cluster (groupe de machines Wormhole).   
Une fois mont√©, ce syst√®me de fichier, int√©gr√© nativement, ne diff√®re pas des autres fichiers de la machine.  
> [!NOTE] Pour un utilisateur, il n'y a aucune diff√©rence entre un dossier de fichiers locaux et un dossier Wormhole.   
> Il en va de m√™me les logiciels et les applications, les fichiers se comportant comme des fichiers locaux normaux, aucune adaptation n'est n√©c√©ssaire.  

#### Pour les entreprises :
Adapt√© aux besoins de grande √©chelle, Wormhole permet de monter en un claquement de doigt une infrastructure puissante :
- **Massive**, lib√©r√©e de la centralisation sur un serveur, la croissance n'a pas de limite.  
- **Performante**, tirant parti de toute la puissance mise √† disposition de mani√®re optimis√©e, √©vitant la consomation inutile.  
- **S√©curis√©e** contre les pertes de donn√©es (m√™me en cas de panne).  
- **Sans interruption de service**, m√™me en cas de panne, m√™me lors de modification du r√©seau.  
- **Flexible**, avec modification facile de l'infrastructure sans interruption de service.  
- **Native**, sans besoin d'adapter les applications et services d√©j√† pr√©sents.  
- **Adapt√©e** √† toutes les √©chelles, du petit r√©seau local d'une startup jusqu'aux grandes infrastructures internationales.  

> [!IMPORTANT] La configuration simple, claire et d√©clarative permet d'√©viter l'erreur humaine.   
> Une fois lanc√©e, l'exp√©rience sera fluide et fiable pour tous les services.  
> Le r√©seau peut √™tre modifi√©, des machines ajout√©es ou retir√©es sans interrompre le service.   
> L'entreprise peut facilement d√©finir sa gestion de s√©curit√© pour la concervation des donn√©es, ainsi que ses [plans de continuit√© d'activit√© informatique](https://fr.wikipedia.org/wiki/Plan_de_continuit%C3%A9_d%27activit%C3%A9_(informatique)) pour r√©sister aux incidents mineurs comme majeurs.  

> [!TIP] Evolutif / Scalable
> La nature adaptive de Wormhole le rend ouvert √† des utilisations vari√©es.   
> **L√©ger**, ne demande pas de configuration minimale puissante.   
> **Optimis√©**, il tirera parti des serveurs les plus capables.   

### Exemples d'utilisations (User Stories) :
> [!WARNING] Vocabulaire utilis√© :
> - **Cluster** : D√©signe le groupe de machines (nodes) connect√©es sur un m√™me r√©seau Wormhole.   
> - **Node** : D√©signe une machine individuelle faisant partie d'un r√©seau.   
> - **Pod** : D√©signe la partie d'une node d√©di√©e √† un cluster (un m√™me node pouvant participer √† plusieurs clusters ind√©pendants).   

> ‚ûï**Startup / PME dans la cybers√©curit√©**   
> Petite √©quipe, n'a pas de p√¥le DSI pour g√©rer de l'infrastructure.   
> N'utilise pas de cloud externe afin de garder la souverainet√© de ses donn√©es.   
> H√©berge ses donn√©es sur ses quelques (ex. 3) petits serveurs NAS.  
> - Souhaite simplifier l'organisation de ses donn√©es. (Actuellement √©parpill√©es sur les diff√©rents NAS).
> - Souhaite assurer l'int√©grit√© de ses donn√©es en cas de panne.
> - N'a pas de temps ni d'√©quipe √† consacrer √† cette gestion des donn√©es. (Organisation, sauvegarde, acc√®s...)
> - Aimerait une solution qui pourra croitre avec l'entreprise.
>
> **Solution Wormhole :**
> - Les machines d'un cluster sont "fusionn√©es". Pour l'utilisateur final, il n'y a qu'une racine (/) peu importe le nombre de machines individuelles. Libre √† lui de cr√©er les dossiers et l'organisation qu'il souhaite.  
> - La configuration des strat√©gies d'int√©grit√© est tr√®s compl√®te, elle permet d'anticiper et de r√©agir aux impr√©vus. Voici quelques exemples :
>   - L'option de redondance stocke la quantit√© demand√©e de copies d'un m√™me fichier sur plusieurs machines. Plus il y a de copies, moins le risque de perte est important en cas de panne.  
>   - Les options gestion de crise ([PCI](https://fr.wikipedia.org/wiki/Plan_de_continuit%C3%A9_d%27activit%C3%A9_(informatique))) permettent pr√©voir la posture √† adopter si trop de machines tombent pour continuer le fonctionnement normal.  
> - La cr√©ation d'un cluster est faisable rapidement m√™me par un d√©butant, et ne demande pas de gestion une fois en place.  
> - La modification d'un cluster ne n√©c√©ssite pas sa suppression ni m√™me d'arr√™t temporaire, il s'√©quilibre automatiquement lors de l'ajout ou du retrait d'une node.  
>   Il est donc facilement portable sur une infrastructure croissante.  
<br>
___

> ‚ûï**Laboratoire**   
> Equipe sp√©cialis√©e, a des serveurs et machine puissantes, mais ce n'est pas le coeur de m√©tier.   
> Proc√®de √† des simulations et analyses, g√©n√©rant des flux tr√®s importants de donn√©es.   
> N'utilise pas de cloud externe, incompatible avec ses besoins de performance.   
> D√©tient des machines puissantes mais sp√©cialis√©es (Ordinateurs pour simulation GPU, Ordinateurs pour analyse CPU, serveurs de stockage massifs).  
> - A de grands besoins de performances.  
> - Souhaiterait que plusieurs machines distinctes puissent analyser un m√™me set de donn√©es.  
> - Les donn√©es sont g√©n√©r√©es, analys√©es et supprim√©es au jour le jour, la perte en cas de panne n'est pas un probl√®me.  
> - A des besoins tr√®s changeants (oscille r√©guli√®rement entre quelques Go et quelques dixaines de To) et aimerait pouvoir allouer ses ressources au jour le jour.  
>
> **Solution Wormhole :**
> - Stocke intelligemment les donn√©es l√† o√π elles sont le plus demand√©es. Propose un syst√®me de cache pour acc√©l√©rer le syst√®me.  
> - Chaque machine du cluster a en effet le m√™me set de donn√©es.  
> - La configuration permet totalement d'optimiser le cluster pour la vitesse et non pour l'int√©grit√© au long terme.  
> - La rapidit√© et simplicit√© de mise en place d'un cluster permet totalement de monter, utiliser et supprimer un cluster pour une seule utilisation.  
>   De plus, il suffit de garder le fichier de configuration sous la main pour recr√©er le cluster en une commande.  
<br>
___

> ‚ûï**Service web**   
> Entreprise r√©cente venant d'exploser ! Ce nouveau r√©seau social permet de partager non pas des photos mais des scans 3D !
> Le r√©seau est atypique mais poss√®de d√©j√† 10.000 utilisateurs r√©guliers ! Stocker tous ces posts p√®se lourd !
> - A un besoin grandissant de place.  
> - A un besoin contrast√© de performance. Les ressources devraient √™tres prioris√©es pour les posts en tendances plut√¥t que les posts anciens et rarement vus.  
> - A besoin d'un service ininterrompu m√™me en cas de panne.  
> - A des exigences d'int√©grit√© autour du minimum l√©gal (environ 3 copies)
>
> **Solution Wormhole :**
> - Utilise toutes les ressources qui lui sont offertes, et en permet un ajout facile.  
> - La configuration des syst√®mes de cache et d'affinit√©s permet de distinguer les serveurs rapides (SSD) et massifs (HDD) et d'utiliser au mieux leur potentiel.  
> - Le cluster maintenant install√© sur une telle quantit√© de serveurs, la redondance et l'√©quilibrage automatique rendent une interruption de service ou une perte de donn√©es virtuellement impossibles.  

<br>

Une fois le syst√®me mis en place, tout fonctionne automatiquement, garantissant une utilisation simple et sans accroc.   
La configuration par fichier est r√©utilisable et partageable. Sa claret√© la rend facile √† comprendre et maintenir m√™me des ann√©es apr√®s sa mise en place.  
La plasticit√© du r√©seau le rend fiable, adaptable et modifiable sans mesures compliqu√©es.  

### Pour les particuliers
La nature **flexible** de Wormhole lui permet un usage pratique m√™me chez les particuliers.   
Marre de chercher vos documents, photos et projets entre votre NAS, votre ordinateur fixe et votre ordinateur portable ?   
Montez en quelques minutes un r√©seau Wormhole, et vos diff√©rents appareils ne font plus qu'un. Vos donn√©es sont disponibles sur tous comme si elles y √©taient !   
> [!IMPORTANT] Une fois install√©, on oublie tr√®s vite la pr√©sence de Wormhole.   
> Et pourtant, l'enfer de chercher ses donn√©es sur diff√©rents appareils, les synchroniser ou les sauvegarder est maintenant de l'histoire ancienne.   
> Wormhole fait tout pour vous üòé   
> On vous a vol√© votre pc portable ? **Vous n'avez pas perdu vos donn√©es.**   
> Votre NAS d√©raille ? **Vous n'avez pas perdu vos donn√©es.**   
> Votre ordinateur fixe brule ?! **Vous n'avez pas perdu vos donn√©es !**   
> Vous avez un nouvel appareil ? **Une commande, et tout est g√©r√©.**   

___

## Sp√©cification d√©taill√©e
Cette partie liste toutes les fonctionalit√©s pr√©vues.

### Interface native

Pour une interaction avec le cluster de mani√®re instinctive, l‚Äôacc√®s aux donn√©es se fait par l‚Äôinterface d‚Äôun dossier virtuel mont√© par Wormhole. Cela permet de garder les m√™mes moyens d‚Äôinteraction avec les donn√©es que avec tout autre syst√®me de fichier. Ces dossiers virtuels sont permis par les technologies natives telles que FUSE (Linux) ou WinFSP (Windows).  

### Int√©gration Universelle

Une des priorit√©s de Wormhole est de rendre le cluster accessible par le plus d‚Äôappareils possible afin que le disque virtuel puisse √™tre compatible avec un maximum de m√©thodes de travail. 
Nos objectifs prioritaires pour l‚ÄôEIP sont une int√©gration sur les plateformes suivantes :
- Linux
- Windows
- Mac

Fuse supportant aussi Android fait d‚Äôandroid une plateforme secondaire int√©ressante √† impl√©menter.  

Pour simplifier l‚Äôacc√®s aux plateformes non support√©es nativement, une image Docker sera d√©velopp√©e.  
Cette image sera propos√©e avec une configuration Kubernetes pour faciliter notre entr√©e dans le monde existant de l‚Äôinformatique distribu√©e.  

Chaque impl√©mentation sera parfaitement compatible, peu importe sa plateforme. La m√™me configuration et les m√™mes param√®tres sont utilis√©s, renforcant la nature universelle du projet.   

### Configuration

Notre projet veut allier rapidit√© de mise en place et extensibilit√© de configuration.  
Pour r√©pondre √† ces objectifs, nous optons pour la configuration par fichiers. Cette m√©thode a d√©j√† fait ses preuves pour des services comme Docker et Kubernetes, en permettant le partage, la r√©utilisation et le versionning. 
Nous pensons utiliser le format TOML, alliant clart√© et modernit√©, et bien int√©gr√© dans l'environnement Rust.  

La configuration se veut la plus compl√®te possible pour moduler tous les aspects du cluster. Elle serait donc √† plusieurs niveaux :
- Niveau du cluster pour le comportement g√©n√©ral.  
- Niveau Pod avec les informations locales et les affinit√©s propres au pod
- Niveau par fichier pour sp√©cifier des exceptions dans leur comportement.  

Voici une liste d‚Äôexemples de champs de configurations qui seraient mis √† disposition de l‚Äôutilisateur.  
*Cette liste n‚Äôest pas exhaustive ou d√©finitive.* Notre objectif est de permettre de configurer tout ce qui peut l‚Äô√™tre, ce qui explique que la majorit√© des champs de configuration sp√©cifiques seront d√©finis au cours du projet.  

**Configuration g√©n√©rale :**
- Nom unique du cluster
- Nombre de redondances par fichier
- Strat√©gie d‚Äôajout (accepter les nouvelles nodes)
- Taille maximale du stockage propos√©
- Administration (qui peut modifier la configuration g√©n√©rale)
- Strat√©gie de panne
  - Si elle n‚Äôentrave pas le fonctionnement ou l‚Äôint√©grit√©
  - Si elle entrave l‚Äôint√©grit√© (manque de redondances, mais aucun fichier perdu)
  - Si elle entrave le fonctionnement (fichiers manquants)

**Configuration par Pod :**
- Limite d‚Äôespace de stockage
- Cache local (propension √† garder des copies locales pour acc√©l√©rer l‚Äôusage)
- Affinit√©s (prioriser ou √©viter un pod pour une t√¢che)
  - Stockage des redondances
  - Stockage des nouveaux fichiers
  - Stockage des fichiers les plus demand√©s
  - Stockage des fichiers les moins demand√©s
- Strat√©gie de panne locale (r√©action si d√©connect√© du r√©seau)

**Configuration par fichier :**
- Conserver (force ce Pod √† conserver une version locale)
- Ne pas mettre en cache
- Lecture seule
- Nombre de redondances

### Distribution de donn√©es

Avec Wormhole, lors de la lecture d‚Äôun fichier qui n‚Äôest pas pr√©sent localement sur la machine, les donn√©es seront t√©l√©charg√©es de la machine h√¥te √† la vol√©e. Cela offre plusieurs possibilit√©es :
- Agir √† distance sur le fichier pendant tout le processus (streaming).  
- Cr√©er une copie locale du fichier pendant son usage, avant d‚Äôexporter les mises √† jour sur le r√©seau.  

Agir √† distance est plus lent (latence) et utilise de la bande passante, mais poss√®de le b√©n√©fice de ne pas utiliser d‚Äôespace disque.  
Utiliser une copie locale utilise de l'espace disque, mais permet une performance accrue.  

L‚Äôextensibilit√© de la configuration permet √† l‚Äôutilisateur de param√©trer ce comportement (et d‚Äôautres comportements similaires).  
Il est aussi important de noter que de mani√®re automatique, Wormhole stockera les fichiers sur les nodes le demandant souvent, optimisant ainsi le syst√®me entier.  


### Strat√©gies de gestion (tol√©rance de panne, redondance et int√©grit√©, performance‚Ä¶)

La gestion des donn√©es est une question complexe, et elle l‚Äôest encore plus de grandes infrastructures telles que celles que Wormhole peut op√©rer. Ce n‚Äôest pas pour rien que les entreprises ont des √©quipes enti√®res consacr√©es au sujet.  

Les exigences pouvant changer du tout au tout selon le cas d‚Äôusage, Wormhole permet de configurer des strat√©gies √† adopter face √† diff√©rents sujets.  

#### Conflits de donn√©es :

La modification simultan√©e d‚Äôun m√™me fichier par plusieurs nodes peut causer des conflits. Il n‚Äôexiste pas de m√©thode de r√©solution de conflits parfaite et universelle. 
L‚Äôutilisateur pourra alors choisir parmi une liste de strat√©gies qui contiendra (sans s‚Äôy limiter) :
- Ecraser (garder la version √©crite en dernier)
- Garder deux copies

#### Int√©grit√© des donn√©es et service ininterrompu (cas g√©n√©ral) :

Il est g√©n√©ralement important d‚Äôassurer l‚Äôint√©grit√© de ses donn√©es en cas de panne. R√©partir des copies des fichiers sur des machines diff√©rentes du r√©seau permet de garantir leur int√©grit√© en cas de d√©faillance.  
Non seulement cela, mais cette r√©plication permet au r√©seau de continuer son service sans interruption ou disparition de fichiers, m√™me temporaire, lors d'une malfonction.  

Ce proc√©d√© porte le nom de redondance et a tout de m√™me le d√©faut de consommer un espace disque important.  
Selon son usage, l‚Äôutilisateur pourra activer ou non ce proc√©d√© et choisir le nombre de r√©plicas par fichier.  
G√©n√©rer un nombre important de copies peut √™tre une op√©ration lourde pour le cluster. L‚Äôutilisateur pourra donc moduler la fr√©quence de mise √† jour des copies.  
Le syst√®me placera judicieusement ces copies l√† o√π elles sont le plus utilis√©es pour am√©liorer les performances.

#### Int√©grit√© et plan de continuit√© (cas de crise) :

La d√©centralisation et l‚Äôusage de la redondance r√©duisent grandement la probabilit√© d‚Äôincident majeur.  
Cependant, Wormhole permet de d√©finir les strat√©gies √† adopter en cas de malfonction g√©n√©ralis√©e.  

Les situations sont divis√©es en trois cat√©gories : 
- **Situation favorable** :  
Pas de pertes de fichiers, le cluster dispose de l‚Äôespace n√©cessaire pour se r√©√©quilibrer et recr√©er les redondances manquantes.  
*Abord√© dans la section **int√©grit√© des donn√©es et service ininterrompu (cas g√©n√©ral)***

- **Situation mitig√©e** :  
  Pas de pertes de fichiers, mais le cluster manque d‚Äôespace pour s‚Äô√©quilibrer et recr√©er la redondance n√©cessaire.  
  
- **Situation grave** :  
Fichiers manquants sur le r√©seau, fonctionnement habituel entrav√©.  

Pour chaque situation, l‚Äôutilisateur peut configurer une r√©action appropri√©e.  
Exemples de r√©actions (non exhaustif) : 
- Ralentir / limiter le trafic
- Geler le r√©seau (lecture seule) jusqu‚Äô√† r√©solution du probl√®me ou action de l‚Äôadministrateur.
- Baisser le nombre de redondances pour augmenter l‚Äôespace libre et poursuivre le service autant que possible.
- Stopper tout.

### Optimisation et r√©partition des charges

La structure d√©centralis√©e en maillage mutualise les capacit√©s et offre de belles perspectives d‚Äôoptimisation de la performance.  
Le syst√®me sera capable de g√©rer ‚Äúintelligemment‚Äù son infrastructure, par exemple :
- Placer les fichiers et leur redondances sur les nodes les utilisant le plus.
- Transferts parall√®les (t√©l√©charger diff√©rentes parties d‚Äôun m√™me fichier depuis deux nodes ou plus, doublant la vitesse de transfert. Il en va de m√™me pour l‚Äôupload).  
- R√©partition des op√©rations lourdes.  
*Exemple* : si le nombre de redondances est √©lev√©, chaque node fera le transfert √† seulement deux autres, qui feront de m√™me, etc, √©vitant ainsi √† une seule node de faire tous les transferts.  

L‚Äôutilisateur pourra aussi moduler ses besoins pour soulager le r√©seau.  
*Exemple* : R√©duire la fr√©quence de r√©plication des fichiers, pour √©viter de propager une op√©ration lourde sur le cluster √† chaque √©dition.  

### Flexibilit√© et fonctions additionnelles
Le cluster peut √™tre modifi√© sans √™tre interrompu. Cela facilite les √©volutions et permet :
- L‚Äôajout de nouvelles nodes
- Le retrait de nodes
- La modification de la configuration

Le cluster s'√©quilibre automatiquement selon le nouveau contexte, sans perturber les services pouvant d√©pendre des donn√©es.  

Il est aussi possible de cr√©er des Pods dit ‚ÄúClients‚Äù. Ceux-ci peuvent acc√©der aux fichiers du cluster sans pour autant devenir une maille du r√©seau.  
Ils peuvent alors se connecter ou d√©connecter √† la vol√©e sans perturber le syst√®me, ce qui les rend adapt√©s √† un d√©ploiement √† grande √©chelle. *(Par exemple, les ordinateurs portables des collaborateurs de l‚Äôentreprise.)*


## Sp√©cification Non-Technique

Sujets de d√©velopment:

***Obligatoire :***

### √âvaluer et Int√©grer les nouvelles technologies
Nous utiliserons une stack technique **r√©cente**, avec une communaut√© active et **ax√©e performance / s√©curit√©**.  
> [!TIP] Rust nous parrait le choix de langage le plus appropri√©.  
> Nous resterons √† l'√©coute des √©volutions de ce langage comme des autres pour ajuster nos choix.  

**Nous suivrons l'apparition de nouvelles plateformes** et de leur pertinence pour une potentielle int√©gration native.  
> [!NOTE] Les plateformes prioritaires sont actuellement :
> - Linux
> - Windows
> - Mac


**Nous explorerons les diff√©rents protocoles r√©seau qui pourraient nous servir au mieux**, tant pour leur vitesse que pour leur fiabilit√©.   
Cela va de soit aussi pour les protocoles d'acc√®s.  
> [!IMPORTANT] Dans le cadre de l'EIP, nous utiliserons les protocoles natifs pour les syst√®mes pr√©c√©dement cit√©s.  
> Mais nous sommes ouverts √† l'int√©gration future de protocoles ouverts pour √©tendre nos compatibilit√©s.  


Nous tiendrons un environnement de d√©veloppement √† jour pour acc√©l√©rer les temps d‚Äôit√©rations.  

<br>

___

***Optionnels :***
### Prot√©ger et am√©liorer notre technologie
**Nous s√©lectionnerons et appliquerons une licence de d√©veloppement open source qui servira au mieux notre projet.**   
> [!NOTE] Nous r√©fl√©chissons √† des licences ouvertes pour les particuliers et payantes pour l'usage commercial / d'entreprises.   
> Ces licences ont le b√©n√©fice de ne pas entraver la d√©mocratisation du projet tout en ouvrant la possibilit√© de le rentabiliser.  


Nous validerons soigneusement nos d√©pendances afin de :
- Respecter leurs licences
- Respecter nos objectifs de l√©geret√©, performance et multiplateforme
- Limiter notre surface d'attaque
___
### Entretenir les contributions par la communaut√©
**Nous voulons obtenir rapidement le soutien de la communaut√©.**  
Cela passe par plusieurs mesures :

#### - Utilisation plaisante et accessible
Bien que notre outil reste technique et qu'il ne disposera pas de notion "UI/UX" √† proprement parler, nous ferons de notre mieux pour le rendre intuitif d√®s la premi√®re utilisation, et surtout pour les besoins courrants et simples. Tout cela afin de ne pas d√©courager les personnes pouvant s'int√©r√©sser au projet.  
> [!TIP] L'environnement de d√©veloppement Rust est une bonne inspiration.  
> Rust est intrasequement une notion technique, mais la "developer experience" est une pr√©occupation.  
> - La documentation est claire.  
> - Le compilateur d√©taille et explique les erreurs ou warnings de mani√®re claire.  
> - Vient avec une suite d'outils (formatting, cross-compilation, int√©gration Visual Studio Code...)
>
>
> Tout ceci joue probablement une grande part dans la popularit√© de Rust, et est inspirant pour un projet comme le notre.  

> [!CAUTION] Notre EIP reste un EIP technique.  
> L'exp√©rience utilisateur fera partie de nos pr√©occupations car elle constitue une bonne strat√©gie, mais elle reste au second plan face aux objectifs techniques pr√©cis√©s dans notre sp√©cification.   
> Les objectifs "qualit√©" (documentation claire, CLI bien pens√©e) seront bien sur int√©gr√©s, mais les objectifs additionnels (ex. suite d'outils) ne feront pas partie des sprints ou objectifs de l'EIP.  

#### - Claret√© technique
Nous ciblerons un public qui souhaite des am√©liorations au projet et poss√®de la volont√© de les faire.   
Cela implique :
- Maintenir une documentation technique publique et claire, pour faciliter le d√©veloppement par des tiers.  
- Notre projet sera publique sur GitHub et incitera √† la contribution.  
- La RoadMap sera publi√©e pour donner √† chaque contributeur potentiel une id√©e de l'avancement et de l'activit√© du projet.  
- Dans la mesure du possible, nous parlerons de notre projet sur des groupes internet centr√©s autour du sujet (Reddit, Discord...)